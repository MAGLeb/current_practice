{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    " \n",
    "\n",
    "def evaluate_model(X, y, model):\n",
    "#     cv = KFold(n_splits=4, random_state=42)\n",
    "#     scorer = make_scorer(f1_score, average='weighted')\n",
    "#     scores = cross_val_score(model, X, y, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "#     return scores\n",
    "\n",
    "    features_train, features_test, target_train, target_test = train_test_split(\n",
    "        X, y, random_state=42, test_size=0.25)\n",
    "    \n",
    "    model.fit(features_train, target_train)\n",
    "    predicted = model.predict(features_test)\n",
    "\n",
    "    return f1_score(predicted, target_test, average='weighted')\n",
    " \n",
    "def get_models():\n",
    "    models, names, grids = list(), list(), list()\n",
    "    \n",
    "    #     n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = list(range(1, 16, 4))\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    bootstrap = [True, False]\n",
    "\n",
    "    grid_rfc = {\n",
    "#         'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'bootstrap': bootstrap,\n",
    "    }\n",
    "    \n",
    "    models.append(RandomForestClassifier(n_estimators=50, random_state=42))\n",
    "    names.append('RF')\n",
    "    grids.append(grid_rfc)\n",
    "    \n",
    "\n",
    "    grid_linearDiscriminant = {\n",
    "        'solver': ['svd', 'lsqr', 'eigen'],\n",
    "        'shrinkage': np.arange(0, 1, 0.01)\n",
    "    }\n",
    "    \n",
    "    grids.append(grid_linearDiscriminant)\n",
    "    models.append(LinearDiscriminantAnalysis())\n",
    "    names.append('LDA')\n",
    "    \n",
    "    \n",
    "    grid_logistic = {\n",
    "        'penalty' : ['l1', 'l2'],\n",
    "        'C' : [0.1, 1, 10],\n",
    "        'class_weight' : ['balanced', None],\n",
    "    }\n",
    "    \n",
    "    grids.append(grid_logistic)\n",
    "    models.append(LogisticRegression(random_state=42))\n",
    "    names.append('LR')\n",
    "    \n",
    "    \n",
    "    depth_range = range(1, 10)\n",
    "    leaf_range = range(1,15)\n",
    "\n",
    "    grid_dtc = {\n",
    "        'max_depth': depth_range,\n",
    "        'min_samples_leaf': leaf_range\n",
    "    }\n",
    "    \n",
    "    grids.append(grid_dtc)\n",
    "    models.append(DecisionTreeClassifier(min_samples_split=10, random_state=42))\n",
    "    names.append('DT')\n",
    "    \n",
    "    return models, names, grids\n",
    "\n",
    "def model_grid_search(X, y, model, grid_params):\n",
    "    features_train, features_test, target_train, target_test = train_test_split(\n",
    "        X, y, random_state=42, test_size=0.25)\n",
    "        \n",
    "    scorer = make_scorer(f1_score, average='weighted')\n",
    "    grid_search = RandomizedSearchCV(estimator=model, param_distributions=grid_params, cv=3, scoring=scorer, error_score=0)\n",
    "    grid_result = grid_search.fit(features_train, target_train)\n",
    "    best_estimator = grid_result.best_estimator_\n",
    "    \n",
    "    predicted = best_estimator.predict(features_test)\n",
    "    \n",
    "    score = f1_score(predicted, target_test, average='weighted')\n",
    "\n",
    "    return [score, best_estimator, predicted]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('new_data.csv')\n",
    "data = data.set_index('hash_inn')\n",
    "data = data[:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data['okved2'] != -1]\n",
    "test_data = data[data['okved2'] == -1]\n",
    "\n",
    "test_data = test_data.drop(['okved2'], axis=1)\n",
    "\n",
    "features = train_data.reset_index().drop(['okved2', 'hash_inn'], axis=1)\n",
    "target = train_data['okved2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('count', 0)</th>\n",
       "      <th>('count', 1)</th>\n",
       "      <th>('count', 2)</th>\n",
       "      <th>('count', 3)</th>\n",
       "      <th>('count', 4)</th>\n",
       "      <th>('count', 5)</th>\n",
       "      <th>('count', 6)</th>\n",
       "      <th>('count', 7)</th>\n",
       "      <th>('count', 8)</th>\n",
       "      <th>('count', 9)</th>\n",
       "      <th>...</th>\n",
       "      <th>('week', 81).1</th>\n",
       "      <th>('week', 82).1</th>\n",
       "      <th>('week', 83).1</th>\n",
       "      <th>('week', 84).1</th>\n",
       "      <th>('week', 85).1</th>\n",
       "      <th>('week', 86).1</th>\n",
       "      <th>('week', 87).1</th>\n",
       "      <th>('week', 88).1</th>\n",
       "      <th>('week', 89).1</th>\n",
       "      <th>('week', 90).1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.107103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.391959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.378141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26871</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26872</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26873</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.996825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26875 rows Ã— 535 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ('count', 0)  ('count', 1)  ('count', 2)  ('count', 3)  ('count', 4)  \\\n",
       "0               0.0           0.0           0.0           0.0           0.0   \n",
       "1               0.0           0.0           0.0           0.0           0.0   \n",
       "2               0.0           0.0           0.0           0.0           0.0   \n",
       "3               0.0           0.0           0.0           0.0           0.0   \n",
       "4               0.0           0.0           0.0           0.0           0.0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "26870           0.0           0.0           0.0           0.0           0.0   \n",
       "26871           0.0           0.0           0.0           0.0           0.0   \n",
       "26872           0.0           0.0           0.0           0.0           0.0   \n",
       "26873           0.0           0.0           0.0           0.0           0.0   \n",
       "26874           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "       ('count', 5)  ('count', 6)  ('count', 7)  ('count', 8)  ('count', 9)  \\\n",
       "0               0.0           0.0           0.0           0.0           0.0   \n",
       "1               0.0           0.0           0.0           0.0           0.0   \n",
       "2               0.0           0.0           0.0           0.0           0.0   \n",
       "3               0.0           0.0           0.0           0.0           0.0   \n",
       "4               0.0           0.0           0.0           0.0           0.0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "26870           0.0           0.0           0.0           0.0           0.0   \n",
       "26871           0.0           0.0           0.0           0.0           0.0   \n",
       "26872           0.0           0.0           0.0           0.0           0.0   \n",
       "26873           0.0           0.0           0.0           0.0           0.0   \n",
       "26874           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "       ...  ('week', 81).1  ('week', 82).1  ('week', 83).1  ('week', 84).1  \\\n",
       "0      ...             0.0             0.0             0.0        0.000000   \n",
       "1      ...             0.0             0.0             0.0        0.000000   \n",
       "2      ...             0.0             0.0             0.0        0.000000   \n",
       "3      ...             0.0             0.0             0.0        6.391959   \n",
       "4      ...             0.0             0.0             0.0        0.000000   \n",
       "...    ...             ...             ...             ...             ...   \n",
       "26870  ...             0.0             0.0             0.0        0.000000   \n",
       "26871  ...             0.0             0.0             0.0        0.000000   \n",
       "26872  ...             0.0             0.0             0.0        0.000000   \n",
       "26873  ...             0.0             0.0             0.0        0.000000   \n",
       "26874  ...             0.0             0.0             0.0        0.000000   \n",
       "\n",
       "       ('week', 85).1  ('week', 86).1  ('week', 87).1  ('week', 88).1  \\\n",
       "0            0.000000             0.0             0.0             0.0   \n",
       "1            0.000000             0.0             0.0             0.0   \n",
       "2            6.107103             0.0             0.0             0.0   \n",
       "3            0.000000             0.0             0.0             0.0   \n",
       "4            0.000000             0.0             0.0             0.0   \n",
       "...               ...             ...             ...             ...   \n",
       "26870        2.378141             0.0             0.0             0.0   \n",
       "26871        0.000000             0.0             0.0             0.0   \n",
       "26872        0.000000             0.0             0.0             0.0   \n",
       "26873        0.000000             0.0             0.0             0.0   \n",
       "26874        5.996825             0.0             0.0             0.0   \n",
       "\n",
       "       ('week', 89).1  ('week', 90).1  \n",
       "0                 0.0             0.0  \n",
       "1                 0.0             0.0  \n",
       "2                 0.0             0.0  \n",
       "3                 0.0             0.0  \n",
       "4                 0.0             0.0  \n",
       "...               ...             ...  \n",
       "26870             0.0             0.0  \n",
       "26871             0.0             0.0  \n",
       "26872             0.0             0.0  \n",
       "26873             0.0             0.0  \n",
       "26874             0.0             0.0  \n",
       "\n",
       "[26875 rows x 535 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4414289028067734"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score([12 for _ in range(len(target_test))], target_test, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4225461327750963"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(features_train, target_train)\n",
    "predicted = model.predict(features_test)\n",
    "\n",
    "f1_score(predicted, target_test, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    6152\n",
       "34     284\n",
       "14      89\n",
       "52      27\n",
       "4       23\n",
       "20      16\n",
       "60      16\n",
       "39      13\n",
       "57       9\n",
       "24       6\n",
       "55       6\n",
       "26       6\n",
       "59       5\n",
       "40       5\n",
       "67       5\n",
       "8        5\n",
       "11       4\n",
       "6        4\n",
       "47       4\n",
       "7        4\n",
       "22       3\n",
       "68       3\n",
       "61       3\n",
       "78       3\n",
       "21       3\n",
       "75       3\n",
       "56       2\n",
       "65       2\n",
       "41       2\n",
       "3        2\n",
       "27       2\n",
       "76       1\n",
       "9        1\n",
       "29       1\n",
       "53       1\n",
       "10       1\n",
       "62       1\n",
       "31       1\n",
       "0        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predicted).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, names, grids = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RF 0.290\n",
      ">LDA 0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LR 0.423\n",
      ">DT 0.188\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    if names[i] not in results:\n",
    "        scores = evaluate_model(features, target, models[i])\n",
    "        results[names[i]] = scores\n",
    "    else:\n",
    "        scores = results[names[i]]\n",
    "    print('>%s %.3f' % (names[i], np.mean(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RF': 0.28973419496341385,\n",
       " 'LDA': 0.3732831793174768,\n",
       " 'LR': 0.4225461327750963,\n",
       " 'DT': 0.18805789043948729}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_grid = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RF 0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 463, in fit\n",
      "    raise NotImplementedError('shrinkage not supported')\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LDA 0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/magleb/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LR 0.422\n",
      ">DT 0.413\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    model, grid, name = models[i], grids[i], names[i]\n",
    "\n",
    "    if name not in results_grid:\n",
    "        scores, best_estimator, predicted = model_grid_search(features, target, model, grid)\n",
    "        results_grid[name] = [scores, best_estimator, predicted]\n",
    "    else:\n",
    "        scores, best_estimator, predicted = results_grid[name]\n",
    "\n",
    "    print('>%s %.3f' % (name, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RF': [0.4365369835642605,\n",
       "  RandomForestClassifier(bootstrap=False, min_samples_leaf=2, n_estimators=50,\n",
       "                         random_state=42),\n",
       "  array([14, 12, 12, ..., 12, 12, 12])],\n",
       " 'LDA': [0.41757785073492354,\n",
       "  LinearDiscriminantAnalysis(shrinkage=0.81, solver='lsqr'),\n",
       "  array([12, 12, 12, ..., 12, 12, 12])],\n",
       " 'LR': [0.42173671396232815,\n",
       "  LogisticRegression(C=0.1, random_state=42),\n",
       "  array([12, 12, 12, ..., 12, 12, 12])],\n",
       " 'DT': [0.41342095927566097,\n",
       "  DecisionTreeClassifier(max_depth=8, min_samples_split=10, random_state=42),\n",
       "  array([14, 12, 12, ..., 52, 12, 12])]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44384112549375554"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_features='sqrt', min_samples_leaf=15,\n",
    "                         min_samples_split=4, n_estimators=200, random_state=42)\n",
    "model.fit(features_train, target_train)\n",
    "predicted = model.predict(features_test)\n",
    "f1_score(predicted, target_test, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('new_data.csv')\n",
    "data = data.set_index('hash_inn')\n",
    "\n",
    "train_data = data[data['okved2'] != -1]\n",
    "test_data = data[data['okved2'] == -1]\n",
    "\n",
    "test_data = test_data.drop(['okved2'], axis=1)\n",
    "\n",
    "features = train_data.reset_index().drop(['okved2', 'hash_inn'], axis=1)\n",
    "target = train_data['okved2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('count', 0)</th>\n",
       "      <th>('count', 1)</th>\n",
       "      <th>('count', 2)</th>\n",
       "      <th>('count', 3)</th>\n",
       "      <th>('count', 4)</th>\n",
       "      <th>('count', 5)</th>\n",
       "      <th>('count', 6)</th>\n",
       "      <th>('count', 7)</th>\n",
       "      <th>('count', 8)</th>\n",
       "      <th>('count', 9)</th>\n",
       "      <th>...</th>\n",
       "      <th>('week', 81).1</th>\n",
       "      <th>('week', 82).1</th>\n",
       "      <th>('week', 83).1</th>\n",
       "      <th>('week', 84).1</th>\n",
       "      <th>('week', 85).1</th>\n",
       "      <th>('week', 86).1</th>\n",
       "      <th>('week', 87).1</th>\n",
       "      <th>('week', 88).1</th>\n",
       "      <th>('week', 89).1</th>\n",
       "      <th>('week', 90).1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.107103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.391959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161410</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.070286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161411</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161412</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.062019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161413</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.976119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161415 rows Ã— 535 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ('count', 0)  ('count', 1)  ('count', 2)  ('count', 3)  ('count', 4)  \\\n",
       "0                0.0           0.0           0.0           0.0           0.0   \n",
       "1                0.0           0.0           0.0           0.0           0.0   \n",
       "2                0.0           0.0           0.0           0.0           0.0   \n",
       "3                0.0           0.0           0.0           0.0           0.0   \n",
       "4                0.0           0.0           0.0           0.0           0.0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "161410           0.0           0.0           0.0           0.0           0.0   \n",
       "161411           0.0           0.0           0.0           0.0           0.0   \n",
       "161412           0.0           0.0           0.0           0.0           0.0   \n",
       "161413           0.0           0.0           0.0           0.0           0.0   \n",
       "161414           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "        ('count', 5)  ('count', 6)  ('count', 7)  ('count', 8)  ('count', 9)  \\\n",
       "0                0.0           0.0           0.0           0.0           0.0   \n",
       "1                0.0           0.0           0.0           0.0           0.0   \n",
       "2                0.0           0.0           0.0           0.0           0.0   \n",
       "3                0.0           0.0           0.0           0.0           0.0   \n",
       "4                0.0           0.0           0.0           0.0           0.0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "161410           0.0           0.0           0.0           0.0           0.0   \n",
       "161411           0.0           0.0           0.0           0.0           0.0   \n",
       "161412           0.0           0.0           0.0           0.0           0.0   \n",
       "161413           0.0           0.0           0.0           0.0           0.0   \n",
       "161414           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "        ...  ('week', 81).1  ('week', 82).1  ('week', 83).1  ('week', 84).1  \\\n",
       "0       ...             0.0             0.0             0.0        0.000000   \n",
       "1       ...             0.0             0.0             0.0        0.000000   \n",
       "2       ...             0.0             0.0             0.0        0.000000   \n",
       "3       ...             0.0             0.0             0.0        6.391959   \n",
       "4       ...             0.0             0.0             0.0        0.000000   \n",
       "...     ...             ...             ...             ...             ...   \n",
       "161410  ...             0.0             0.0             0.0        6.070286   \n",
       "161411  ...             0.0             0.0             0.0        0.000000   \n",
       "161412  ...             0.0             0.0             0.0        4.062019   \n",
       "161413  ...             0.0             0.0             0.0        0.000000   \n",
       "161414  ...             0.0             0.0             0.0        0.000000   \n",
       "\n",
       "        ('week', 85).1  ('week', 86).1  ('week', 87).1  ('week', 88).1  \\\n",
       "0             0.000000             0.0             0.0             0.0   \n",
       "1             0.000000             0.0             0.0             0.0   \n",
       "2             6.107103             0.0             0.0             0.0   \n",
       "3             0.000000             0.0             0.0             0.0   \n",
       "4             0.000000             0.0             0.0             0.0   \n",
       "...                ...             ...             ...             ...   \n",
       "161410        0.000000             0.0             0.0             0.0   \n",
       "161411        0.000000             0.0             0.0             0.0   \n",
       "161412        0.000000             0.0             0.0             0.0   \n",
       "161413        3.976119             0.0             0.0             0.0   \n",
       "161414        0.000000             0.0             0.0             0.0   \n",
       "\n",
       "        ('week', 89).1  ('week', 90).1  \n",
       "0                  0.0             0.0  \n",
       "1                  0.0             0.0  \n",
       "2                  0.0             0.0  \n",
       "3                  0.0             0.0  \n",
       "4                  0.0             0.0  \n",
       "...                ...             ...  \n",
       "161410             0.0             0.0  \n",
       "161411             0.0             0.0  \n",
       "161412             0.0             0.0  \n",
       "161413             0.0             0.0  \n",
       "161414             0.0             0.0  \n",
       "\n",
       "[161415 rows x 535 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('count', 0)</th>\n",
       "      <th>('count', 1)</th>\n",
       "      <th>('count', 2)</th>\n",
       "      <th>('count', 3)</th>\n",
       "      <th>('count', 4)</th>\n",
       "      <th>('count', 5)</th>\n",
       "      <th>('count', 6)</th>\n",
       "      <th>('count', 7)</th>\n",
       "      <th>('count', 8)</th>\n",
       "      <th>('count', 9)</th>\n",
       "      <th>...</th>\n",
       "      <th>('week', 81).1</th>\n",
       "      <th>('week', 82).1</th>\n",
       "      <th>('week', 83).1</th>\n",
       "      <th>('week', 84).1</th>\n",
       "      <th>('week', 85).1</th>\n",
       "      <th>('week', 86).1</th>\n",
       "      <th>('week', 87).1</th>\n",
       "      <th>('week', 88).1</th>\n",
       "      <th>('week', 89).1</th>\n",
       "      <th>('week', 90).1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hash_inn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.772733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.322906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260485</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.195624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260500</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260514</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260515</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78654 rows Ã— 535 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ('count', 0)  ('count', 1)  ('count', 2)  ('count', 3)  \\\n",
       "hash_inn                                                           \n",
       "0                  0.0           0.0           0.0           0.0   \n",
       "2                  0.0           0.0           0.0           0.0   \n",
       "4                  0.0           0.0           0.0           0.0   \n",
       "6                  0.0           0.0           0.0           0.0   \n",
       "9                  0.0           0.0           0.0           0.0   \n",
       "...                ...           ...           ...           ...   \n",
       "260485             0.0           0.0           0.0           0.0   \n",
       "260487             0.0           0.0           0.0           0.0   \n",
       "260500             0.0           0.0           0.0           0.0   \n",
       "260514             0.0           0.0           0.0           0.0   \n",
       "260515             0.0           0.0           0.0           0.0   \n",
       "\n",
       "          ('count', 4)  ('count', 5)  ('count', 6)  ('count', 7)  \\\n",
       "hash_inn                                                           \n",
       "0                  7.0           0.0           2.0           1.0   \n",
       "2                  0.0           0.0           0.0           0.0   \n",
       "4                  0.0           0.0           0.0           0.0   \n",
       "6                  0.0           0.0           0.0           0.0   \n",
       "9                  0.0           0.0           0.0           0.0   \n",
       "...                ...           ...           ...           ...   \n",
       "260485             0.0           0.0           0.0           0.0   \n",
       "260487             0.0           0.0           0.0           0.0   \n",
       "260500             0.0           0.0           0.0           0.0   \n",
       "260514             0.0           0.0           0.0           0.0   \n",
       "260515             0.0           0.0           0.0           0.0   \n",
       "\n",
       "          ('count', 8)  ('count', 9)  ...  ('week', 81).1  ('week', 82).1  \\\n",
       "hash_inn                              ...                                   \n",
       "0                  0.0           0.0  ...             0.0             0.0   \n",
       "2                  0.0           0.0  ...             0.0             0.0   \n",
       "4                  0.0           0.0  ...             0.0             0.0   \n",
       "6                  0.0           0.0  ...             0.0             0.0   \n",
       "9                  0.0           0.0  ...             0.0             0.0   \n",
       "...                ...           ...  ...             ...             ...   \n",
       "260485             0.0           0.0  ...             0.0             0.0   \n",
       "260487             0.0           0.0  ...             0.0             0.0   \n",
       "260500             0.0           0.0  ...             0.0             0.0   \n",
       "260514             0.0           0.0  ...             0.0             0.0   \n",
       "260515             0.0           0.0  ...             0.0             0.0   \n",
       "\n",
       "          ('week', 83).1  ('week', 84).1  ('week', 85).1  ('week', 86).1  \\\n",
       "hash_inn                                                                   \n",
       "0               0.000000        5.772733             0.0        5.322906   \n",
       "2               0.000000        0.000000             0.0        0.000000   \n",
       "4               0.000000        0.000000             0.0        0.000000   \n",
       "6               0.000000        0.000000             0.0        0.000000   \n",
       "9               0.000000        0.000000             0.0        0.000000   \n",
       "...                  ...             ...             ...             ...   \n",
       "260485          0.000000        0.000000             0.0        0.000000   \n",
       "260487          5.195624        0.000000             0.0        0.000000   \n",
       "260500          0.000000        0.000000             0.0        0.000000   \n",
       "260514          0.000000        0.000000             0.0        0.000000   \n",
       "260515          0.000000        0.000000             0.0        0.000000   \n",
       "\n",
       "          ('week', 87).1  ('week', 88).1  ('week', 89).1  ('week', 90).1  \n",
       "hash_inn                                                                  \n",
       "0                    0.0             0.0             0.0             0.0  \n",
       "2                    0.0             0.0             0.0             0.0  \n",
       "4                    0.0             0.0             0.0             0.0  \n",
       "6                    0.0             0.0             0.0             0.0  \n",
       "9                    0.0             0.0             0.0             0.0  \n",
       "...                  ...             ...             ...             ...  \n",
       "260485               0.0             0.0             0.0             0.0  \n",
       "260487               0.0             0.0             0.0             0.0  \n",
       "260500               0.0             0.0             0.0             0.0  \n",
       "260514               0.0             0.0             0.0             0.0  \n",
       "260515               0.0             0.0             0.0             0.0  \n",
       "\n",
       "[78654 rows x 535 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 12, 12, ..., 12, 12, 12])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_features='sqrt', min_samples_leaf=15,\n",
    "                         min_samples_split=4, n_estimators=70, random_state=42)\n",
    "model.fit(features, target)\n",
    "predicted = model.predict(test_data)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      2,      4,      6,      9,     12,     15,     19,\n",
       "                22,     38,\n",
       "            ...\n",
       "            260475, 260476, 260482, 260483, 260484, 260485, 260487, 260500,\n",
       "            260514, 260515],\n",
       "           dtype='int64', name='hash_inn', length=78654)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_inn</th>\n",
       "      <th>okved2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78649</th>\n",
       "      <td>260485</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78650</th>\n",
       "      <td>260487</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78651</th>\n",
       "      <td>260500</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78652</th>\n",
       "      <td>260514</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78653</th>\n",
       "      <td>260515</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78654 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hash_inn  okved2\n",
       "0             0      12\n",
       "1             2      12\n",
       "2             4      12\n",
       "3             6      12\n",
       "4             9      12\n",
       "...         ...     ...\n",
       "78649    260485      12\n",
       "78650    260487      12\n",
       "78651    260500      12\n",
       "78652    260514      12\n",
       "78653    260515      12\n",
       "\n",
       "[78654 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulted_df = pd.DataFrame(index=test_data.index, data=predicted)\n",
    "resulted_df = resulted_df.reset_index()\n",
    "resulted_df.columns = ['hash_inn', 'okved2']\n",
    "resulted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulted_df.to_csv('MaksimovGleb-SberbankIndustry.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
